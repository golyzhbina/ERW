{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e4e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.layers import UpSampling2D, concatenate\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras import Model\n",
    "from numpy import array\n",
    "from os import listdir\n",
    "from os.path import join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6126d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "way_to_original_train = r\"E:\\folder_J\\images\\jpg\\train\\images_jpg\"\n",
    "way_to_edited_train = r\"E:\\folder_J\\images\\jpg\\train\\images_edited_jpg\"\n",
    "\n",
    "\n",
    "def load_images(way: str, lst_of_name: list, flag: bool) -> array:\n",
    "\n",
    "    images = []\n",
    "    for name in lst_of_name:\n",
    "        image = load_img(join(way, name),\n",
    "                         color_mode=\"grayscale\",\n",
    "                         target_size=(1150, 180))\n",
    "        image = img_to_array(image) / 255\n",
    "\n",
    "        images.append(image)\n",
    "\n",
    "    return array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2bead2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(1150, 180, 1), batch_size=None)\n",
    "conv1_1 = Conv2D(8, (3, 3), padding=\"same\", activation=\"relu\")(input_layer)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_1)\n",
    "\n",
    "conv2_1 = Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(5, 2))(conv2_1)\n",
    "\n",
    "conv3_1 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(pool2)\n",
    "# pool3 = MaxPooling2D(pool_size=(5, 3))(conv3_2)\n",
    "\n",
    "conc4 = concatenate([UpSampling2D(size=(5, 2))(conv3_1), conv2_1])\n",
    "conv4_2 = Conv2D(32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(conc4)\n",
    "\n",
    "conc5 = concatenate([UpSampling2D(size=(2, 2))(conv4_2), conv1_1])\n",
    "conv5_1 = Conv2D(16, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(conc5)\n",
    "\n",
    "conv4 = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(conv5_1)\n",
    "\n",
    "model = Model(inputs=[input_layer], outputs=[conv4])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[MeanIoU(num_classes=50), \"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c05c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_u.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df3c765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 343s 17s/step - loss: 0.2294 - mean_io_u: 0.4984 - accuracy: 0.9786\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 342s 17s/step - loss: 0.0612 - mean_io_u: 0.4984 - accuracy: 0.9789\n",
      "finished\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 342s 17s/step - loss: 0.0400 - mean_io_u: 0.4984 - accuracy: 0.9796\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 341s 17s/step - loss: 0.0349 - mean_io_u: 0.4984 - accuracy: 0.9796\n",
      "finished\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 342s 17s/step - loss: 0.0240 - mean_io_u: 0.4984 - accuracy: 0.9794\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 341s 17s/step - loss: 0.0137 - mean_io_u: 0.4984 - accuracy: 0.9802\n",
      "finished\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 341s 17s/step - loss: 0.0107 - mean_io_u: 0.4985 - accuracy: 0.9811\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 341s 17s/step - loss: 0.0091 - mean_io_u: 0.4985 - accuracy: 0.9813\n",
      "finished\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 343s 17s/step - loss: 0.0086 - mean_io_u: 0.4984 - accuracy: 0.9814\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 342s 17s/step - loss: 0.0080 - mean_io_u: 0.4984 - accuracy: 0.9815\n",
      "finished\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 340s 17s/step - loss: 0.0074 - mean_io_u: 0.4985 - accuracy: 0.9820\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 340s 17s/step - loss: 0.0071 - mean_io_u: 0.4985 - accuracy: 0.9821\n",
      "finished\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 339s 17s/step - loss: 0.0069 - mean_io_u: 0.4985 - accuracy: 0.9820\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 341s 17s/step - loss: 0.0067 - mean_io_u: 0.4985 - accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "i, j = 0, 1000\n",
    "for _ in range(7):\n",
    "    \n",
    "    images_name_train = listdir(way_to_original_train)\n",
    "    images_name_train = sorted(images_name_train, key=lambda *args: random.random())[i:j]\n",
    "\n",
    "    x_train = load_images(way_to_original_train, images_name_train, False)\n",
    "    y_train = load_images(way_to_edited_train, images_name_train, True)\n",
    "    print(\"finished\")\n",
    "    \n",
    "    his = model.fit(x_train, y_train, batch_size=50, epochs=2)\n",
    "    model.save('model_u.h5')\n",
    "    \n",
    "    i += 1000\n",
    "    j += 1000\n",
    "    if i == 7000:\n",
    "        j = 7804\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a6ae8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.jpg\n",
      "[[0.19451198 0.09105033 0.0749231  ... 0.04359952 0.06217757 0.14489797]\n",
      " [0.09575582 0.02320141 0.01657838 ... 0.0059275  0.01115516 0.05537364]\n",
      " [0.08301824 0.01586789 0.01110893 ... 0.00295013 0.00594661 0.03581381]\n",
      " ...\n",
      " [0.12822914 0.05856496 0.05416325 ... 0.02144867 0.03111422 0.05828443]\n",
      " [0.18936723 0.09707144 0.08368233 ... 0.04096705 0.0566743  0.08943063]\n",
      " [0.28587693 0.15641409 0.13536125 ... 0.08926147 0.10327268 0.1569106 ]]\n",
      "[[50. 23. 19. ... 11. 16. 37.]\n",
      " [24.  6.  4. ...  2.  3. 14.]\n",
      " [21.  4.  3. ...  1.  2.  9.]\n",
      " ...\n",
      " [33. 15. 14. ...  5.  8. 15.]\n",
      " [48. 25. 21. ... 10. 14. 23.]\n",
      " [73. 40. 35. ... 23. 26. 40.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "name = listdir(r\"E:\\folder_J\\images\\jpg\\test\\images_for_test_original\")\n",
    "print(name[0])\n",
    "img = load_img(join(r\"E:\\folder_J\\images\\jpg\\test\\images_for_test_original\", name[0]),\n",
    "                         color_mode=\"grayscale\",\n",
    "                         target_size=(1150, 180))\n",
    "img_a = img\n",
    "img = img_to_array(img) / 255\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "res = model.predict(img, batch_size=None)\n",
    "res = np.reshape(res, (1150, 180))\n",
    "print(res)\n",
    "for i in range(len(res)):\n",
    "    res[i] = np.array(list(map(lambda x: round(x * 255, 0), res[i])))\n",
    "print(res)\n",
    "i_res = Image.fromarray(res)\n",
    "i_res.show()\n",
    "img_a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0568c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_u.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c99377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(\"model_u.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08859a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from numpy import array\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "way_to_original_train = r\"E:\\folder_J\\images\\jpg\\test\\images_for_test_original\"\n",
    "way_to_edited_train = r\"E:\\folder_J\\images\\jpg\\test\\images for_test_edited\"\n",
    "\n",
    "\n",
    "def load_images(way: str, lst_of_name: list, flag: bool) -> array:\n",
    "\n",
    "    images = []\n",
    "    for name in lst_of_name:\n",
    "        image = load_img(join(way, name),\n",
    "                         color_mode=\"grayscale\",\n",
    "                         target_size=(1150, 180))\n",
    "        image = img_to_array(image) / 255\n",
    "\n",
    "        images.append(image)\n",
    "\n",
    "    return array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30817670",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_name_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6564/3931051828.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mway_to_original_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_name_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mway_to_edited_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_name_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"finished\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images_name_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train = load_images(way_to_original_train, images_name_train, False)\n",
    "y_train = load_images(way_to_edited_train, images_name_train, True)\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba044076",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
